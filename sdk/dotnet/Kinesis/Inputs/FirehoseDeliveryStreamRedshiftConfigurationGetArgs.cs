// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.Kinesis.Inputs
{

    public sealed class FirehoseDeliveryStreamRedshiftConfigurationGetArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The CloudWatch Logging Options for the delivery stream. More details are given below.
        /// </summary>
        [Input("cloudwatchLoggingOptions")]
        public Input<Inputs.FirehoseDeliveryStreamRedshiftConfigurationCloudwatchLoggingOptionsGetArgs>? CloudwatchLoggingOptions { get; set; }

        /// <summary>
        /// The jdbcurl of the redshift cluster.
        /// </summary>
        [Input("clusterJdbcurl", required: true)]
        public Input<string> ClusterJdbcurl { get; set; } = null!;

        /// <summary>
        /// Copy options for copying the data from the s3 intermediate bucket into redshift, for example to change the default delimiter. For valid values, see the [AWS documentation](http://docs.aws.amazon.com/firehose/latest/APIReference/API_CopyCommand.html)
        /// </summary>
        [Input("copyOptions")]
        public Input<string>? CopyOptions { get; set; }

        /// <summary>
        /// The data table columns that will be targeted by the copy command.
        /// </summary>
        [Input("dataTableColumns")]
        public Input<string>? DataTableColumns { get; set; }

        /// <summary>
        /// The name of the table in the redshift cluster that the s3 bucket will copy to.
        /// </summary>
        [Input("dataTableName", required: true)]
        public Input<string> DataTableName { get; set; } = null!;

        /// <summary>
        /// The password for the username above.
        /// </summary>
        [Input("password", required: true)]
        public Input<string> Password { get; set; } = null!;

        /// <summary>
        /// The data processing configuration.  More details are given below.
        /// </summary>
        [Input("processingConfiguration")]
        public Input<Inputs.FirehoseDeliveryStreamRedshiftConfigurationProcessingConfigurationGetArgs>? ProcessingConfiguration { get; set; }

        /// <summary>
        /// After an initial failure to deliver to Amazon Elasticsearch, the total amount of time, in seconds between 0 to 7200, during which Firehose re-attempts delivery (including the first attempt).  After this time has elapsed, the failed documents are written to Amazon S3.  The default value is 300s.  There will be no retry if the value is 0.
        /// </summary>
        [Input("retryDuration")]
        public Input<int>? RetryDuration { get; set; }

        /// <summary>
        /// The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in the same account you use for Kinesis Data Firehose. Cross-account roles aren't allowed.
        /// </summary>
        [Input("roleArn", required: true)]
        public Input<string> RoleArn { get; set; } = null!;

        /// <summary>
        /// The configuration for backup in Amazon S3. Required if `s3_backup_mode` is `Enabled`. Supports the same fields as `s3_configuration` object.
        /// </summary>
        [Input("s3BackupConfiguration")]
        public Input<Inputs.FirehoseDeliveryStreamRedshiftConfigurationS3BackupConfigurationGetArgs>? S3BackupConfiguration { get; set; }

        /// <summary>
        /// Defines how documents should be delivered to Amazon S3.  Valid values are `FailedEventsOnly` and `AllEvents`.  Default value is `FailedEventsOnly`.
        /// </summary>
        [Input("s3BackupMode")]
        public Input<string>? S3BackupMode { get; set; }

        /// <summary>
        /// The username that the firehose delivery stream will assume. It is strongly recommended that the username and password provided is used exclusively for Amazon Kinesis Firehose purposes, and that the permissions for the account are restricted for Amazon Redshift INSERT permissions.
        /// </summary>
        [Input("username", required: true)]
        public Input<string> Username { get; set; } = null!;

        public FirehoseDeliveryStreamRedshiftConfigurationGetArgs()
        {
        }
    }
}
